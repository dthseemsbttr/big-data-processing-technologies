{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Параллельные вычисления"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Автор задач: Блохин Н.В. (NVBlokhin@fa.ru)__\n",
    "\n",
    "Материалы:\n",
    "* Макрушин С.В. Лекция \"Параллельные вычисления\"\n",
    "* https://docs.python.org/3/library/multiprocessing.html\n",
    "    * https://docs.python.org/3/library/multiprocessing.html#multiprocessing.Process\n",
    "    * https://docs.python.org/3/library/multiprocessing.html#multiprocessing.pool.Pool\n",
    "    * https://docs.python.org/3/library/multiprocessing.html#multiprocessing.Queue\n",
    "* https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html\n",
    "* https://numpy.org/doc/stable/reference/generated/numpy.array_split.html\n",
    "* https://nalepae.github.io/pandarallel/\n",
    "    * https://github.com/nalepae/pandarallel/blob/master/docs/examples_windows.ipynb\n",
    "    * https://github.com/nalepae/pandarallel/blob/master/docs/examples_mac_linux.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задачи для совместного разбора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandarallel in c:\\anaconda\\lib\\site-packages (1.6.3)\n",
      "Requirement already satisfied: psutil in c:\\anaconda\\lib\\site-packages (from pandarallel) (5.7.0)\n",
      "Requirement already satisfied: dill>=0.3.1 in c:\\anaconda\\lib\\site-packages (from pandarallel) (0.3.6)\n",
      "Requirement already satisfied: pandas>=1 in c:\\anaconda\\lib\\site-packages (from pandarallel) (1.4.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\anaconda\\lib\\site-packages (from pandas>=1->pandarallel) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\anaconda\\lib\\site-packages (from pandas>=1->pandarallel) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.18.5; platform_machine != \"aarch64\" and platform_machine != \"arm64\" and python_version < \"3.10\" in c:\\anaconda\\lib\\site-packages (from pandas>=1->pandarallel) (1.20.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\anaconda\\lib\\site-packages (from python-dateutil>=2.8.1->pandas>=1->pandarallel) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandarallel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Посчитайте, сколько раз встречается буква \"a\" в файлах [\"xaa\", \"xab\", \"xac\", \"xad\"]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "files = [f\"{name}.txt\" for name in [\"xaa\", \"xab\", \"xac\", \"xad\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_a(file):\n",
    "    with open(file, \"r\", encoding=\"utf8\") as fp:\n",
    "        text = fp.read().lower()\n",
    "    res = Counter(text)[\"a\"]\n",
    "    print(file, res)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xaa.txt 2599627\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m<timed eval>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n",
      "\u001b[1;32m<ipython-input-56-ebd026bf6a33>\u001b[0m in \u001b[0;36mcount_a\u001b[1;34m(file)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcount_a\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"utf8\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m         \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"a\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda\\lib\\codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;31m# decode input (taking the buffer into account)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 322\u001b[1;33m         \u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconsumed\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    323\u001b[0m         \u001b[1;31m# keep undecoded input until the next call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mconsumed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "[count_a(f) for f in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting count_a.py\n"
     ]
    }
   ],
   "source": [
    "%%file count_a.py\n",
    "from collections import Counter\n",
    "\n",
    "def count_a(file):\n",
    "    with open(file, \"r\", encoding=\"utf8\") as fp:\n",
    "        text = fp.read().lower()\n",
    "    res = Counter(text)[\"a\"]\n",
    "    print(file, res)\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from count_a import count_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mmap\u001b[1;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[0;32m    362\u001b[0m         \u001b[1;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    363\u001b[0m         '''\n\u001b[1;32m--> 364\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    365\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    763\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 765\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    766\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mready\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    760\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 762\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    763\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    556\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 558\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    559\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    300\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 302\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with multiprocessing.Pool(processes=4) as pool:\n",
    "    res = pool.map(count_a, files)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting count_a_q.py\n"
     ]
    }
   ],
   "source": [
    "%%file count_a_q.py\n",
    "from collections import Counter\n",
    "\n",
    "def count_a_q(file, queue):\n",
    "    with open(file, \"r\", encoding=\"utf8\") as fp:\n",
    "        text = fp.read().lower()\n",
    "    res = Counter(text)[\"a\"]\n",
    "    print(file, res)\n",
    "    queue.put(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from count_a_q import count_a_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.29 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1460452, 2599868, 2599627, 2605911]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "processes = []\n",
    "queue = multiprocessing.Queue()\n",
    "\n",
    "for f in files:\n",
    "    process = multiprocessing.Process(target=count_a_q, args=(f, queue))\n",
    "    processes.append(process)\n",
    "    process.start()\n",
    "\n",
    "res = []\n",
    "while len(res) < 4:\n",
    "    if not queue.empty():\n",
    "        res.append(queue.get())\n",
    "    \n",
    "for p in processes:\n",
    "    p.join()\n",
    "    \n",
    "# ...\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Выведите на экран слова из файла words_alpha, в которых есть две или более буквы \"e\" подряд."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "words = (\n",
    "    pd.read_csv(\"words_alpha.txt\", header=None)[0]\n",
    "    .dropna()\n",
    "    .sample(frac=1, replace=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def f(s):\n",
    "    return bool(re.findall(r\"e{2,}\", s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 968 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "247337    preerection\n",
       "95907         eellike\n",
       "256114       pugarees\n",
       "264621       reeledid\n",
       "95930          eerock\n",
       "             ...     \n",
       "265799      regreeted\n",
       "143440        honoree\n",
       "118674      freewheel\n",
       "30312         beefily\n",
       "160082         jageer\n",
       "Name: 0, Length: 7091, dtype: object"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "words[words.map(f)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 6 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n",
      "\n",
      "WARNING: You are on Windows. If you detect any issue with pandarallel, be sure you checked out the Troubleshooting page:\n",
      "https://nalepae.github.io/pandarallel/troubleshooting/\n"
     ]
    }
   ],
   "source": [
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting for_map.py\n"
     ]
    }
   ],
   "source": [
    "%%file for_map.py\n",
    "import re\n",
    "\n",
    "def f(s):\n",
    "    return bool(re.findall(r\"e{2,}\", s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from for_map import f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "words[words.parallel_map(f)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Лабораторная работа 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__При решении данных задач не подразумевается использования циклов или генераторов Python в ходе работы с пакетами `numpy` и `pandas`, если в задании не сказано обратного. Решения задач, в которых для обработки массивов `numpy` или структур `pandas` используются явные циклы (без согласования с преподавателем), могут быть признаны некорректными и не засчитаны.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. В каждой строке файла `tag_nsteps.csv` хранится информация о тэге рецепта и количестве шагов в этом рецепте в следующем виде:\n",
    "\n",
    "```\n",
    "tags,n_steps\n",
    "hungarian,2\n",
    "european,6\n",
    "occasion,4\n",
    "pumpkin,4\n",
    "................\n",
    "```\n",
    "\n",
    "Всего в исходном файле хранится чуть меньше, чем 71 млн, строк. Разбейте файл `tag_nsteps.csv` на несколько (например, 8) примерно одинаковых по объему файлов c названиями `tag_nsteps_*.csv`, где вместо символа `*` указан номер очередного файла. Каждый файл имеет структуру, аналогичную оригинальному файлу (включая заголовок).\n",
    "\n",
    "__Важно__: здесь и далее вы не можете загружать в память весь исходный файл сразу. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, chunk in enumerate(pd.read_csv('tag_nsteps.csv', chunksize=71000000//8)):\n",
    "    chunk.to_csv(f'tag_nsteps_{index+1}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Напишите функцию, которая принимает на вход название файла, созданного в результате решения задачи 1, считает для каждого тэга сумму по столбцу `n_steps` и количество строк c этим тэгом, и возвращает результат в виде словаря. Ожидаемый вид итогового словаря:\n",
    "\n",
    "```\n",
    "{\n",
    "    '1-day-or-more': {'sum': 56616, 'count': 12752},\n",
    "    '15-minutes-or-less': {'sum': 195413, 'count': 38898},\n",
    "    '3-steps-or-less': {'sum': 187938, 'count': 39711},\n",
    "    ....\n",
    "}\n",
    "```\n",
    "\n",
    "Примените данную функцию к каждому файлу, полученному в задании 1, и соберите результат в виде списка словарей. Не используйте параллельных вычислений. \n",
    "\n",
    "Выведите на экран значение по ключу \"30-minutes-or-less\" для каждого из словарей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tag_sum_count_from_file(file: str) -> dict:\n",
    "    dict_tags = {}\n",
    "    df = pd.read_csv(file)\n",
    "    df_grouped = df.groupby('tags').sum('n_steps')\n",
    "    df_grouped['count'] = df.groupby('tags').count()\n",
    "    df_grouped.columns = ['sum', 'count']\n",
    "    return df_grouped.to_dict(orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [f\"tag_nsteps_{index}.csv\" for index in np.arange(1,9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_sum_list = [get_tag_sum_count_from_file(f) for f in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sum': 348943, 'count': 45605},\n",
       " {'sum': 350194, 'count': 46053},\n",
       " {'sum': 353624, 'count': 46295},\n",
       " {'sum': 347697, 'count': 45621},\n",
       " {'sum': 346528, 'count': 45650},\n",
       " {'sum': 350333, 'count': 46014},\n",
       " {'sum': 346536, 'count': 45814},\n",
       " {'sum': 339350, 'count': 44730}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(lambda x: x['30-minutes-or-less'], tag_sum_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. Напишите функцию, которая объединяет результаты обработки отдельных файлов. Данная функция принимает на вход список словарей, каждый из которых является результатом вызова функции `get_tag_sum_count_from_file` для конкретного файла, и агрегирует эти словари. Не используйте параллельных вычислений.\n",
    "\n",
    "Процедура агрегации словарей имеет следующий вид:\n",
    "$$d_{agg}[k] = \\{sum: \\sum_{i=1}^{n}d_{i}[k][sum], count: \\sum_{i=1}^{n}d_{i}[k][count]\\}$$\n",
    "где $d_1, d_2, ..., d_n$- результат вызова функции `get_tag_sum_count_from_file` для конкретных файлов.\n",
    "\n",
    "Примените данную функцию к результату выполнения задания 2. Выведите на экран результат для тэга \"30-minutes-or-less\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_results(tag_sum_count_list: list) -> dict:\n",
    "    result = {}\n",
    "    for part in tag_sum_count_list:\n",
    "        for tag in part:\n",
    "            if tag in result:\n",
    "                result[tag]['sum'] += part[tag]['sum']\n",
    "                result[tag]['count'] += part[tag]['count']\n",
    "            else:\n",
    "                result[tag] = {'sum': part[tag]['sum'], 'count': part[tag]['count']}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sum': 2783205, 'count': 365782}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_results(tag_sum_list)['30-minutes-or-less']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_sum_count_dict = agg_results(tag_sum_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. Напишите функцию, которая считает среднее значение количества шагов для каждого тэга в словаре, имеющего вид, аналогичный словарям в задаче 2, и возвращает результат в виде словаря . Используйте решения задач 1-3, чтобы получить среднее значение количества шагов каждого тэга для всего датасета, имея результаты обработки частей датасета и результат их агрегации. Выведите на экран результат для тэга \"30-minutes-or-less\".\n",
    "\n",
    "Определите, за какое время задача решается для всего датасета. При замере времени учитывайте время расчета статистики для каждого файла, агрегации результатов и, собственно, вычисления средного. Временем, затрачиваемым на процедуру разбиения исходного файла можно пренебречь."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tag_mean_n_steps(tag_sum_count: dict) -> dict:\n",
    "    result = {}\n",
    "    for tag in tag_sum_count:\n",
    "        result[tag] = tag_sum_count[tag]['sum']/tag_sum_count[tag]['count']\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.608917333275011"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_tag_mean_n_steps(tag_sum_count_dict)[\"30-minutes-or-less\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 7s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7.608917333275011"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "def get_tag_sum_count_from_file(file: str) -> dict:\n",
    "    dict_tags = {}\n",
    "    df = pd.read_csv(file)\n",
    "    df_grouped = df.groupby('tags').sum('n_steps')\n",
    "    df_grouped['count'] = df.groupby('tags').count()\n",
    "    df_grouped.columns = ['sum', 'count']\n",
    "    return df_grouped.to_dict(orient='index')\n",
    "\n",
    "files = [f\"tag_nsteps_{index}.csv\" for index in np.arange(1,9)]\n",
    "tag_sum_list = [get_tag_sum_count_from_file(f) for f in files]\n",
    "\n",
    "def agg_results(tag_sum_count_list: list) -> dict:\n",
    "    result = {}\n",
    "    for part in tag_sum_count_list:\n",
    "        for tag in part:\n",
    "            if tag in result:\n",
    "                result[tag]['sum'] += part[tag]['sum']\n",
    "                result[tag]['count'] += part[tag]['count']\n",
    "            else:\n",
    "                result[tag] = {'sum': part[tag]['sum'], 'count': part[tag]['count']}\n",
    "    return result\n",
    "\n",
    "tag_sum_count_dict = agg_results(tag_sum_list)\n",
    "\n",
    "def get_tag_mean_n_steps(tag_sum_count: dict) -> dict:\n",
    "    result = {}\n",
    "    for tag in tag_sum_count:\n",
    "        result[tag] = tag_sum_count[tag]['sum']/tag_sum_count[tag]['count']\n",
    "    return result\n",
    "\n",
    "get_tag_mean_n_steps(tag_sum_count_dict)[\"30-minutes-or-less\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. Повторите решение задачи 4, распараллелив вызовы функции `get_tag_sum_count_from_file` для различных файлов с помощью `multiprocessing.Pool`. Для обработки каждого файла создайте свой собственный процесс. Выведите на экран результат для тэга \"30-minutes-or-less\". Определите, за какое время задача решается для всех файлов. При замере времени учитывайте время расчета статистики для каждого файла, агрегации результатов и, собственно, вычисления средного. Временем, затрачиваемым на процедуру разбиения исходного файла можно пренебречь."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting get_tag_sum_count_from_file.py\n"
     ]
    }
   ],
   "source": [
    "%%file get_tag_sum_count_from_file.py\n",
    "import pandas as pd\n",
    "\n",
    "def get_tag_sum_count_from_file(file: str) -> dict:\n",
    "    dict_tags = {}\n",
    "    df = pd.read_csv(file)\n",
    "    df_grouped = df.groupby('tags').sum('n_steps')\n",
    "    df_grouped['count'] = df.groupby('tags').count()\n",
    "    df_grouped.columns = ['sum', 'count']\n",
    "    return df_grouped.to_dict(orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_tag_sum_count_from_file import get_tag_sum_count_from_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 15.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7.608917333275011"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "files = [f\"tag_nsteps_{index}.csv\" for index in np.arange(1,9)]\n",
    "\n",
    "with multiprocessing.Pool(processes=8) as pool:\n",
    "    res = pool.map(get_tag_sum_count_from_file, files)\n",
    "\n",
    "def agg_results(tag_sum_count_list: list) -> dict:\n",
    "    result = {}\n",
    "    for part in tag_sum_count_list:\n",
    "        for tag in part:\n",
    "            if tag in result:\n",
    "                result[tag]['sum'] += part[tag]['sum']\n",
    "                result[tag]['count'] += part[tag]['count']\n",
    "            else:\n",
    "                result[tag] = {'sum': part[tag]['sum'], 'count': part[tag]['count']}\n",
    "    return result\n",
    "\n",
    "tag_sum_count_dict = agg_results(res)\n",
    "\n",
    "def get_tag_mean_n_steps(tag_sum_count: dict) -> dict:\n",
    "    result = {}\n",
    "    for tag in tag_sum_count:\n",
    "        result[tag] = tag_sum_count[tag]['sum']/tag_sum_count[tag]['count']\n",
    "    return result\n",
    "\n",
    "get_tag_mean_n_steps(tag_sum_count_dict)[\"30-minutes-or-less\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6\\. Повторите решение задачи 4, распараллелив вычисления функции `get_tag_sum_count_from_file` для различных файлов с помощью `multiprocessing.Process`. Для обработки каждого файла создайте свой собственный процесс. Для обмена данными между процессами используйте `multiprocessing.Queue`.\n",
    "\n",
    "Выведите на экран результат для тэга \"30-minutes-or-less\". Определите, за какое время задача решается для всех файлов. При замере времени учитывайте время расчета статистики для каждого файла, агрегации результатов и, собственно, вычисления средного. Временем, затрачиваемым на процедуру разбиения исходного файла можно пренебречь."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting get_tag_sum_count_from_file.py\n"
     ]
    }
   ],
   "source": [
    "%%file get_tag_sum_count_from_file.py\n",
    "import pandas as pd\n",
    "\n",
    "def get_tag_sum_count_from_file(file: str, queue) -> dict:\n",
    "    dict_tags = {}\n",
    "    df = pd.read_csv(file)\n",
    "    df_grouped = df.groupby('tags').sum('n_steps')\n",
    "    df_grouped['count'] = df.groupby('tags').count()\n",
    "    df_grouped.columns = ['sum', 'count']\n",
    "    queue.put(df_grouped.to_dict(orient='index'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_tag_sum_count_from_file import get_tag_sum_count_from_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 19 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7.608917333275011"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "files = [f\"tag_nsteps_{index}.csv\" for index in np.arange(1,9)]\n",
    "\n",
    "processes = []\n",
    "queue = multiprocessing.Queue()\n",
    "\n",
    "for f in files:\n",
    "    process = multiprocessing.Process(target=get_tag_sum_count_from_file, args=(f, queue))\n",
    "    processes.append(process)\n",
    "    process.start()\n",
    "\n",
    "res = []\n",
    "while len(res) < 8:\n",
    "    if not queue.empty():\n",
    "        res.append(queue.get())\n",
    "    \n",
    "for p in processes:\n",
    "    p.join()\n",
    "    \n",
    "def agg_results(tag_sum_count_list: list) -> dict:\n",
    "    result = {}\n",
    "    for part in tag_sum_count_list:\n",
    "        for tag in part:\n",
    "            if tag in result:\n",
    "                result[tag]['sum'] += part[tag]['sum']\n",
    "                result[tag]['count'] += part[tag]['count']\n",
    "            else:\n",
    "                result[tag] = {'sum': part[tag]['sum'], 'count': part[tag]['count']}\n",
    "    return result\n",
    "\n",
    "tag_sum_count_dict = agg_results(res)\n",
    "\n",
    "def get_tag_mean_n_steps(tag_sum_count: dict) -> dict:\n",
    "    result = {}\n",
    "    for tag in tag_sum_count:\n",
    "        result[tag] = tag_sum_count[tag]['sum']/tag_sum_count[tag]['count']\n",
    "    return result\n",
    "\n",
    "get_tag_mean_n_steps(tag_sum_count_dict)[\"30-minutes-or-less\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7\\. Исследуйте, как влияет количество запущенных одновременно процессов на скорость решения задачи. Узнайте количество ядер вашего процессора $K$. Повторите решение задачи 1, разбив исходный файл на $\\frac{K}{2}$, $K$ и $2K$ фрагментов. Для каждого из разбиений повторите решение задачи 5. Визуализируйте зависимость времени выполнения кода от количества файлов в разбиении. Сделайте вывод в виде текстового комментария."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, chunk in enumerate(pd.read_csv('tag_nsteps.csv', chunksize=71000000//3)):\n",
    "    chunk.to_csv(f'tag_nsteps_{index+1}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting get_tag_sum_count_from_file.py\n"
     ]
    }
   ],
   "source": [
    "%%file get_tag_sum_count_from_file.py\n",
    "import pandas as pd\n",
    "\n",
    "def get_tag_sum_count_from_file(file: str) -> dict:\n",
    "    dict_tags = {}\n",
    "    df = pd.read_csv(file)\n",
    "    df_grouped = df.groupby('tags').sum('n_steps')\n",
    "    df_grouped['count'] = df.groupby('tags').count()\n",
    "    df_grouped.columns = ['sum', 'count']\n",
    "    return df_grouped.to_dict(orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_tag_sum_count_from_file import get_tag_sum_count_from_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.608917333275011\n",
      "23.4 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<TimeitResult : 23.4 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%timeit -n1 -r1 -o\n",
    "\n",
    "files = [f\"tag_nsteps_{index}.csv\" for index in np.arange(1,4)]\n",
    "\n",
    "with multiprocessing.Pool(processes=3) as pool:\n",
    "    res = pool.map(get_tag_sum_count_from_file, files)\n",
    "\n",
    "def agg_results(tag_sum_count_list: list) -> dict:\n",
    "    result = {}\n",
    "    for part in tag_sum_count_list:\n",
    "        for tag in part:\n",
    "            if tag in result:\n",
    "                result[tag]['sum'] += part[tag]['sum']\n",
    "                result[tag]['count'] += part[tag]['count']\n",
    "            else:\n",
    "                result[tag] = {'sum': part[tag]['sum'], 'count': part[tag]['count']}\n",
    "    return result\n",
    "\n",
    "tag_sum_count_dict = agg_results(res)\n",
    "\n",
    "def get_tag_mean_n_steps(tag_sum_count: dict) -> dict:\n",
    "    result = {}\n",
    "    for tag in tag_sum_count:\n",
    "        result[tag] = tag_sum_count[tag]['sum']/tag_sum_count[tag]['count']\n",
    "    return result\n",
    "\n",
    "print(get_tag_mean_n_steps(tag_sum_count_dict)[\"30-minutes-or-less\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.374589499999956"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timek0 = _.average\n",
    "timek0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, chunk in enumerate(pd.read_csv('tag_nsteps.csv', chunksize=71000000//6)):\n",
    "    chunk.to_csv(f'tag_nsteps_{index+1}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting get_tag_sum_count_from_file.py\n"
     ]
    }
   ],
   "source": [
    "%%file get_tag_sum_count_from_file.py\n",
    "import pandas as pd\n",
    "\n",
    "def get_tag_sum_count_from_file(file: str) -> dict:\n",
    "    dict_tags = {}\n",
    "    df = pd.read_csv(file)\n",
    "    df_grouped = df.groupby('tags').sum('n_steps')\n",
    "    df_grouped['count'] = df.groupby('tags').count()\n",
    "    df_grouped.columns = ['sum', 'count']\n",
    "    return df_grouped.to_dict(orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_tag_sum_count_from_file import get_tag_sum_count_from_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.608917333275011\n",
      "14.7 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<TimeitResult : 14.7 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%timeit -n1 -r1 -o\n",
    "\n",
    "files = [f\"tag_nsteps_{index}.csv\" for index in np.arange(1,7)]\n",
    "\n",
    "with multiprocessing.Pool(processes=6) as pool:\n",
    "    res = pool.map(get_tag_sum_count_from_file, files)\n",
    "\n",
    "def agg_results(tag_sum_count_list: list) -> dict:\n",
    "    result = {}\n",
    "    for part in tag_sum_count_list:\n",
    "        for tag in part:\n",
    "            if tag in result:\n",
    "                result[tag]['sum'] += part[tag]['sum']\n",
    "                result[tag]['count'] += part[tag]['count']\n",
    "            else:\n",
    "                result[tag] = {'sum': part[tag]['sum'], 'count': part[tag]['count']}\n",
    "    return result\n",
    "\n",
    "tag_sum_count_dict = agg_results(res)\n",
    "\n",
    "def get_tag_mean_n_steps(tag_sum_count: dict) -> dict:\n",
    "    result = {}\n",
    "    for tag in tag_sum_count:\n",
    "        result[tag] = tag_sum_count[tag]['sum']/tag_sum_count[tag]['count']\n",
    "    return result\n",
    "\n",
    "print(get_tag_mean_n_steps(tag_sum_count_dict)[\"30-minutes-or-less\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.748135999999931"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timek = _.average\n",
    "timek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, chunk in enumerate(pd.read_csv('tag_nsteps.csv', chunksize=71000000//12)):\n",
    "    chunk.to_csv(f'tag_nsteps_{index+1}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting get_tag_sum_count_from_file.py\n"
     ]
    }
   ],
   "source": [
    "%%file get_tag_sum_count_from_file.py\n",
    "import pandas as pd\n",
    "\n",
    "def get_tag_sum_count_from_file(file: str) -> dict:\n",
    "    dict_tags = {}\n",
    "    df = pd.read_csv(file)\n",
    "    df_grouped = df.groupby('tags').sum('n_steps')\n",
    "    df_grouped['count'] = df.groupby('tags').count()\n",
    "    df_grouped.columns = ['sum', 'count']\n",
    "    return df_grouped.to_dict(orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_tag_sum_count_from_file import get_tag_sum_count_from_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.608917333275011\n",
      "18.3 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<TimeitResult : 18.3 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%timeit -n1 -r1 -o\n",
    "\n",
    "files = [f\"tag_nsteps_{index}.csv\" for index in np.arange(1,13)]\n",
    "\n",
    "with multiprocessing.Pool(processes=12) as pool:\n",
    "    res = pool.map(get_tag_sum_count_from_file, files)\n",
    "\n",
    "def agg_results(tag_sum_count_list: list) -> dict:\n",
    "    result = {}\n",
    "    for part in tag_sum_count_list:\n",
    "        for tag in part:\n",
    "            if tag in result:\n",
    "                result[tag]['sum'] += part[tag]['sum']\n",
    "                result[tag]['count'] += part[tag]['count']\n",
    "            else:\n",
    "                result[tag] = {'sum': part[tag]['sum'], 'count': part[tag]['count']}\n",
    "    return result\n",
    "\n",
    "tag_sum_count_dict = agg_results(res)\n",
    "\n",
    "def get_tag_mean_n_steps(tag_sum_count: dict) -> dict:\n",
    "    result = {}\n",
    "    for tag in tag_sum_count:\n",
    "        result[tag] = tag_sum_count[tag]['sum']/tag_sum_count[tag]['count']\n",
    "    return result\n",
    "\n",
    "print(get_tag_mean_n_steps(tag_sum_count_dict)[\"30-minutes-or-less\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.266986999999972"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time2k = _.average\n",
    "time2k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2c62ba7ad90>]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [3, 6, 12]\n",
    "y = [timek0, timek, time2k]\n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.plot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Время выполнения самое быстрое при количестве процессов, равном количестве ядер. \n",
    "#Далее, при возрастании количества процессов больше времени тратится на распараллеливание процессов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8\\. Напишите функцию `parallel_map`, которая принимает на вход серию `s` `pd.Series` и функцию одного аргумента `f` и поэлементно применяет эту функцию к серии, распараллелив вычисления при помощи пакета `multiprocessing`. Логика работы функции `parallel_map` должна включать следующие действия:\n",
    "* разбиение исходной серии на $K$ частей, где $K$ - количество ядер вашего процессора;\n",
    "* параллельное применение функции `f` к каждой части при помощи метода _серии_ `map` при помощи нескольких подпроцессов;\n",
    "* объединение результатов работы подпроцессов в одну серию. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_function(s: pd.Series):\n",
    "    return s.map(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_map(s: pd.Series, f: callable) -> pd.Series:\n",
    "    arr_split = np.array_split(s, 6)\n",
    "    with multiprocessing.Pool(processes=6) as pool:\n",
    "        res = pool.map(f, arr_split)\n",
    "    return pd.concat(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Функция для использования метода серий map отдельно, а parallel_map нужно вызывать с параметрами (s, call_function),\n",
    "#потому что нельзя использовать лямбда функции внутри вызова multiprocessing map, о чем говорит вызов функции ниже"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#arr_split = np.array_split(df['tags'][~df['tags'].isna()], 8)\n",
    "#with multiprocessing.Pool(processes=6) as pool:\n",
    "#    res = pool.map(lambda x: x.map(f), arr_split)\n",
    "#pd.concat(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9\\. Напишите функцию `f`, которая принимает на вход тэг и проверяет, удовлетворяет ли тэг следующему шаблону: `[любое число]-[любое слово]-or-less`. Возьмите любой фрагмент файла, полученный в задании 1, примените функцию `f` при помощи `parallel_map` к столбцу `tags` и посчитайте количество тэгов, подходящих под этот шаблон. Решите ту же задачу, воспользовавшись методом _серий_ `map`. Сравните время и результат выполнения двух решений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('tag_nsteps_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting for_map.py\n"
     ]
    }
   ],
   "source": [
    "%%file for_map.py\n",
    "import re\n",
    "\n",
    "def f(tag: str) -> bool:\n",
    "    patt = re.compile(r\"\\d+-[a-zA-Z]+'?[a-zA-Z]*-or-less\", re.I)\n",
    "    return bool(re.fullmatch(patt, tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from for_map import f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting call_function.py\n"
     ]
    }
   ],
   "source": [
    "%%file call_function.py\n",
    "import pandas as pd\n",
    "import re\n",
    "from for_map import f\n",
    "\n",
    "def call_function(s: pd.Series):\n",
    "    return s.map(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from call_function import call_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9.73 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "170603"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "parallel_map(df['tags'][~df['tags'].isna()], call_function).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 34.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "170603"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df['tags'][~df['tags'].isna()].map(f).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Результат выполнения идентичный, но время выполнения написанной вручную функции parallel_map в три раза быстрее"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10\\. Используя пакет `pandarallel`, примените функцию `f` из задания 9 к столбцу `tags` таблицы, с которой вы работали этом задании. Посчитайте количество тэгов, подходящих под описанный шаблон. Измерьте время выполнения кода. Выведите на экран полученный результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 6 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n",
      "\n",
      "WARNING: You are on Windows. If you detect any issue with pandarallel, be sure you checked out the Troubleshooting page:\n",
      "https://nalepae.github.io/pandarallel/troubleshooting/\n"
     ]
    }
   ],
   "source": [
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from for_map import f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 13.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "170603"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df['tags'][~df['tags'].isna()].parallel_map(f).sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
